---
title: "Module 1: Foundations of AI, Generative Models, NLP, LLMs, Chat Templates, OpenAI, Langchain, Prompt Engineering"
layout: post
---

Discover the essential principles of Artificial Intelligence, Generative AI, and Natural Language Processing — laying the groundwork for understanding Large Language Models (LLMs) and the emerging framework of intelligent agents. These agents, built upon LLMs, are capable of autonomous reasoning, decision-making, and dynamic tool usage, enabling powerful applications across industries, education, and research. This module will progressively introduce foundational concepts that culminate in a clear understanding of how AI agents operate and are built using modern frameworks like LangChain, OpenAI tools, and prompt engineering strategies.


---

# 1. Introduction to Artificial Intelligence

A broad overview of AI, its history, key domains, and the evolution from rule-based systems to data-driven learning.

{% include embed.html url="https://www.youtube.com/embed/D2JY38VShxI" %}

Artificial intelligence is a field of science concerned with building computers and machines that can reason, learn, and act in such a way that would normally require human intelligence or that involves data whose scale exceeds what humans can analyze.

AI is a broad field that encompasses many different disciplines, including computer science, data analytics and statistics, hardware and software engineering, linguistics, neuroscience, and even philosophy and psychology. 
On an operational level for business use, AI is a set of technologies that are based primarily on machine learning and deep learning, used for data analytics, predictions and forecasting, object categorization, natural language processing, recommendations, intelligent data retrieval, and more.

---

# 2. From AI to Generative AI

Learn what makes GenAI different from traditional AI — focusing on systems that can create new content such as text, images, music, and code.

## 2.1 Understanding Generative AI

{% include embed.html url="https://www.youtube.com/embed/G2fqAlgmoPo" %}

<div style="display: flex; gap: 20px; flex-wrap: wrap;">
  <a href="https://news.mit.edu/2023/explained-generative-ai-1109" target="_blank">
    <img src="{{ '/assets/images/mit_news_image.png' | relative_url }}" alt="MIT GenAI"
         style="width: 300px; height: 400px; object-fit: cover; border-radius: 8px;" />
  </a>

  <a href="https://blogs.oracle.com/fusioninsider/post/understand-the-differences-between-ai-genai-and-ml" target="_blank">
    <img src="{{ '/assets/images/oracle_blogs_image.png' | relative_url }}" alt="Oracle AI vs GenAI vs ML"
         style="width: 300px; height: 400px; object-fit: cover; border-radius: 8px;" />
  </a>
</div>

## 2.2 Generative vs. Discriminative Models

Gain a deeper understanding of the conceptual and practical differences between generative models, which are designed to create new data samples that resemble the training data, and discriminative models, which focus on classifying or predicting labels based on input data. This distinction is fundamental to understanding how different types of AI models approach problem-solving and content generation.

<div style="display: flex;">
  <a href="https://developers.google.com/machine-learning/gan/generative" target="_blank">
    <img src="{{ '/assets/images/google_genai.png' | relative_url }}" alt="Google GenAI"
         style="width: 40%; height: auto%; border-radius: 8px;" />
  </a>
</div>

## 2.3 The most popular generative AI applications

**Language**: Text is at the root of many generative AI models and is considered to be the most advanced domain. One of the most popular examples of language-based generative models are called large language models (LLMs). Large language models are being leveraged for a wide variety of tasks, including essay generation, code development, translation, and even understanding genetic sequences.

**Audio**: Music, audio, and speech are also emerging fields within generative AI. Examples include models being able to develop songs and snippets of audio clips with text inputs, recognize objects in videos and create accompanying noises for different video footage, and even create custom music.

**Visual**: One of the most popular applications of generative AI is within the realm of images. This encompasses the creation of 3D images, avatars, videos, graphs, and other illustrations. There’s flexibility in generating images with different aesthetic styles, as well as techniques for editing and modifying generated visuals. Generative AI models can create graphs that show new chemical compounds and molecules that aid in drug discovery, create realistic images for virtual or augmented reality, produce 3D models for video games, design logos, enhance or edit existing images, and more.

**Synthetic data**: Synthetic data is extremely useful to train AI models when data doesn’t exist, is restricted, or is simply unable to address corner cases with the highest accuracy. The development of synthetic data through generative models is perhaps one of the most impactful solutions for overcoming the data challenges of many enterprises. It spans all modalities and use cases and is possible through a process called label efficient learning. Generative AI models can reduce labeling costs by either automatically producing additional augmented training data or by learning an internal representation of the data that facilitates training AI models with less labeled data.

The impact of generative models is wide-reaching, and its applications are only growing. Listed are just a few examples of how generative AI is helping to advance and transform the fields of transportation, natural sciences, and entertainment.

In the automotive industry, generative AI is expected to help create 3D worlds and models for simulations and car development. Synthetic data is also being used to train autonomous vehicles. Being able to road test the abilities of an autonomous vehicle in a realistic 3D world improves safety, efficiency, and flexibility while decreasing risk and overhead.

The field of natural sciences greatly benefits from generative AI. In the healthcare industry, generative models can aid in medical research by developing new protein sequences to aid in drug discovery. Practitioners can also benefit from the automation of tasks such as scribing, medical coding, medical imaging, and genomic analysis. Meanwhile, in the weather industry, generative models can be used to create simulations of the planet and help with accurate weather forecasting and natural disaster prediction. These applications can help to create safer environments for the general population and allow scientists to predict and better prepare for natural disasters.

All aspects of the entertainment industry, from video games to film, animation, world building, and virtual reality, are able to leverage generative AI models to help streamline their content creation process. Creators are using generative models as a tool to help supplement their creativity and work.

<div style="display: flex;">
  <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank">
    <img src="{{ '/assets/images/nvidia_genai.png' | relative_url }}" alt="Nvidia GenAI"
         style="width: 30%; height: auto; border-radius: 8px;" />
  </a>
</div>

---

# 3. Introduction to Natural Language Processing

Delve into the fascinating challenge of teaching machines to understand and generate human language—exploring why this problem is uniquely difficult and how modern approaches are achieving breakthrough capabilities. 

Note: While the linked tutorials may contain coding examples, for this module you should focus on understanding the concepts and challenges of NLP rather than implementing code. The goal is to develop a strong conceptual foundation of why language processing is difficult for machines before attempting technical implementations in future modules.

{% include embed.html url="https://www.youtube.com/embed/videoseries?si=6HDRdbGwbxv0mu6L&amp;list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S" %}

---

# 4. Large Language Models (LLMs)

Large Language Models are at the core of modern generative AI and agents. These models are trained on massive amounts of text data and use deep learning (typically transformers) to generate human-like responses to natural language inputs.

{% include embed.html url="https://www.youtube.com/embed/zizonToFXDs" %}

## 4.1 Capabilities of Large Language Models

### Natural Language Processing
- **Text Generation**: Creating human-like text across diverse formats (articles, stories, emails)
- **Translation**: Converting content between hundreds of languages with contextual awareness
- **Conversation**: Maintaining coherent multi-turn dialogues with contextual understanding
- **Style Adaptation**: Adjusting tone, formality, and complexity to match specific audiences

### Information Processing
- **Summarization**: Condensing lengthy documents while preserving key information
- **Question Answering**: Extracting relevant information to address specific queries
- **Knowledge Synthesis**: Combining information from multiple sources into cohesive responses
- **Content Classification**: Categorizing text based on topic, sentiment, or intent

### Programming Abilities
- **Code Generation**: Writing functional code in numerous programming languages
- **Debugging**: Identifying and fixing errors in existing code
- **Refactoring**: Improving code structure while maintaining functionality
- **Documentation**: Creating clear explanations and technical documentation for code

### Reasoning Capabilities
- **Step-by-Step Problem Solving**: Breaking down complex problems into manageable steps
- **Mathematical Reasoning**: Solving mathematical problems of varying complexity
- **Logical Analysis**: Evaluating arguments for validity and soundness
- **Chain-of-Thought Processing**: Demonstrating intermediate reasoning steps

### Tool Integration
- **Function Calling**: Interfacing with external APIs and services
- **Data Analysis**: Processing structured data to extract insights
- **Workflow Automation**: Coordinating multi-step processes across different systems
- **Multimodal Processing**: Understanding and generating content that combines text with other formats

## 4.2 Limitations and Challenges of LLMs

### Knowledge Constraints
- **Hallucinations**: Generating plausible but factually incorrect information
- **Knowledge Cutoff**: Limited to information available during training
- **Lack of True Understanding**: Statistical pattern matching rather than semantic comprehension
- **Domain Expertise Gaps**: Inconsistent depth of knowledge across specialized fields

### Technical Limitations
- **Context Window Constraints**: Limited ability to reference information beyond a certain window
- **Prompt Sensitivity**: Results varying significantly based on how questions are phrased
- **Computational Requirements**: High resource demands for inference and deployment
- **Scaling Challenges**: Diminishing returns from simply increasing model size

### Reasoning Deficiencies
- **Mathematical Errors**: Inconsistent performance on complex calculations
- **Logical Fallacies**: Susceptibility to errors in multi-step reasoning
- **Common Sense Gaps**: Missing intuitive understanding of physical world constraints
- **Temporal Reasoning Issues**: Difficulties with complex time-based reasoning

#### Ethical Challenges
- **Bias and Fairness**: Perpetuating or amplifying biases present in training data
- **Value Alignment**: Difficulties in capturing nuanced human values across cultures
- **Safety Concerns**: Potential for generating harmful or misleading content
- **Security Vulnerabilities**: Susceptibility to prompt injection and jailbreaking attempts

## 4.3 A More Visual Explanation of LLMs

{% include embed.html url="https://www.youtube.com/embed/LPZh9BOjkQs" %}

---

# 5. Chat Templates, Roles and Interaction Patterns

When interacting with Large Language Models (LLMs), understanding the different conversation roles is essential for effective communication. This guide will help you grasp these concepts before diving into LangChain.

## The Three Key Roles in LLM Conversations

LLMs like *ChatGPT*, *Claude*, or *Gemini* use a structured conversation format with three distinct roles:

## 1. System Role
Think of this as the "behind-the-scenes director" that shapes how the LLM behaves.

- **Purpose**: Sets the overall behavior, personality, and constraints for the AI
- **Not visible** to end users in most interfaces
- **Written by developers** or application designers
- **Sets the stage** for the entire conversation

## 2. User/Human Role 
This is you! The person asking questions and providing input.

- **Provides the prompts** and questions
- **Drives the conversation** forward
- **Can include follow-up questions** or clarifications
- **Determines the direction** of the interaction

## 3. Assistant/AI Role
This is the LLM's response area - where it provides answers.

- **Generates responses** based on both system instructions and user input
- **Maintains conversation context** from previous exchanges
- **Follows the behavior guidelines** established in the system role
- **Formats outputs** according to instructions

## How Roles Work Together in Practice

Let's break down a simple interaction:

```
SYSTEM: You are a helpful math tutor. Explain concepts clearly for middle school students.
USER: What is the Pythagorean theorem?
ASSISTANT: The Pythagorean theorem is a way to find the length of sides in a right triangle. It says that a² + b² = c², where a and b are the shorter sides, and c is the longest side (hypotenuse).
```

In this example:
- The **system role** establishes the AI as a math tutor for middle school students
- The **user role** asks a specific question about geometry
- The **assistant role** responds with an age-appropriate explanation

The video below offers an interesting parallel to the concept of message roles in LLMs. Although it does not explicitly introduce this framework, the first two minutes effectively reflect the dynamics between System, Human, and AI messages. I encourage you to observe closely and draw your own conclusions about the importance of well-defined prompts when interacting with language models—how we frame inputs can greatly influence the clarity, behavior, and quality of the AI's responses.

{% include embed.html url="https://www.youtube.com/embed/RzkD_rTEBYs" %}

## Key Concepts for LangChain Integration

As you prepare to learn LangChain, keep these important points in mind:

1. **Role-based modeling**: LangChain uses this same role structure when building conversation chains

2. **Templating**: You'll often create templates that include placeholders for dynamic content

  ```python
  prompt = ChatPromptTemplate.from_messages([
      ("system", "You are a {role}."),
      ("human", "{question}")
  ])
  ```

3. **Message history**: LangChain lets you maintain conversation context by storing previous exchanges

4. **Chain composition**: You'll learn to build pipelines that process inputs through multiple steps

## Tips for Effective Role Usage

- **Be specific in system instructions**: The more detailed your system role, the better the LLM will follow your requirements
- **Use consistent personas**: Maintain the same "character" throughout a conversation 
- **Consider memory requirements**: Decide if your application needs to remember previous messages
- **Test different role configurations**: Experiment with various system instructions to see what works best

*Check out Hugging Face's Chat Templates documentation to understand different role structures (system, user, assistant) before diving into LangChain implementation. Focus only on the template formats for now, not the implementation details.*

<div style="display: flex;">
  <a href="https://huggingface.co/learn/llm-course/chapter11/2" target="_blank">
    <img src="{{ '/assets/images/hg_chat_templates.png' | relative_url }}" alt="HG Chat Templates"
         style="width: 35%; height: auto; border-radius: 8px;" />
  </a>
</div>

---

# 6. Working with LLM APIs

## **Why OpenAI’s Design Became the Industry Standard**

Before diving into LangChain, it’s crucial to understand the ecosystem of large language model (LLM) APIs—and why OpenAI’s API design has become the de facto standard for the industry.

In this course, we won’t use the OpenAI API directly. Instead, we’ll leverage LangChain’s abstractions (like ChatOpenAI) to interact with models. But knowing the structure of the OpenAI API—and how many other providers follow this same standard—will help you understand what’s happening “under the hood.”

By the end of this module, you’ll understand:

- **What OpenAI-compatible really means** – Why providers like Anthropic and DeepSeek align with OpenAI's API standard

- **The power of abstraction** – How LangChain lets you switch between providers without rewriting your code.

## **Why OpenAI’s API? A De Facto Standard**

OpenAI’s API design — with endpoints like `/v1/chat/completions`, JSON-based request/response format, and parameters like `temperature` and `max_tokens` — has become more than just a product. It’s evolved into a de facto standard for how developers interact with large language models.

OpenAI didn’t just release an API; it introduced a design pattern that many other AI providers have adopted. This happened because:

**Simplicity**:
The API offers a clean, intuitive interface, using concepts like messages (with role and content) that closely map to natural conversation flows. This makes it easy for developers to understand and integrate, even without deep AI knowledge.

**Widespread Adoption**:
Because OpenAI was one of the first and most popular providers, many developers, tools, and companies built solutions assuming OpenAI’s API structure. For other providers, being “OpenAI-compatible” means developers can reuse their existing tools and code—making it easier to attract users.

**Ecosystem Integration**:
Frameworks like LangChain, LlamaIndex, and SDKs like the openai Python library are all designed around OpenAI’s API structure. By following this standard, new providers instantly gain compatibility with these powerful tools, without requiring extra integrations.

## **What "OpenAI-Compatible" Really Means**

When providers like **Anthropic, DeepSeek, Mistral, Maritaca and others** say they are **OpenAI-compatible**, it means: 

**They adopt the same API structure and interface as OpenAI**, but use their own models and infrastructure. Their APIs follow the same endpoints, parameters, and response formats defined by OpenAI, making them interoperable with tools and SDKs designed for OpenAI’s API. This allows you to use OpenAI’s official SDK (or other OpenAI-compatible tools) to interact with their models by simply changing configuration values like the `base_url`, even though OpenAI itself isn’t involved as the provider.

**Zero dependency on OpenAI**: Even though the interface is compatible, the underlying model, servers, and costs are provided by the other company. You’re not relying on OpenAI at all.

Example: Calling Anthropic’s `claude-3-7-sonnet` model, using the OpenAI SDK by simply changing the the `base_url`:

```python
# Using OpenAI’s SDK to call a non-OpenAI model
from openai import OpenAI

client = OpenAI(
  api_key="ANTHROPIC_API_KEY",  # Your Anthropic API key
  base_url="https://api.anthropic.com/v1/"  # Anthropic's API endpoint, Not OpenAI’s URL!
)

response = client.chat.completions.create(
  model="claude-3-7-sonnet-20250219", # Anthropic model name
  messages=[
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Who are you?"}
  ],
)

print(response.choices[0].message.content)
```

*You’re using the OpenAI SDK, but OpenAI itself isn’t involved — the model, infrastructure, and billing are fully managed by Anthropic.*

## **The Power of Abstraction: LangChain**

To future-proof your skills, we’ll use **LangChain**—a framework that goes beyond just OpenAI-compatible APIs.

LangChain provides a unified interface to interact with both OpenAI-compatible providers and providers with entirely different APIs, such as Amazon Bedrock, Cohere, Hugging Face, Azure, Groq, Ollama, and Llama.

- **Avoids vendor lock-in**: You can switch providers just by updating configuration, without rewriting your application logic.

- **Workflow-centric**: You’ll focus on how to integrate LLMs into applications, rather than memorizing the specifics of a single API.

With LangChain, switching between different language models is as simple as changing the class you instantiate, while keeping the rest of your code and logic the same. For example, you can use `ChatOpenAI` to access both OpenAI’s own models and any third-party provider offering an OpenAI-compatible API by simply updating the `base_url` and `api_key`. Likewise, you can use `ChatHuggingFace` to connect to Hugging Face models, or `ChatBedrockConverse` to interact with Amazon Bedrock—each following a similar interface.

This unified approach lets you experiment with different providers and models by simply swapping the class or configuration, without having to rewrite your application logic or workflows.

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    # api_key="...",
    # base_url="...",
)
```

```python
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint

llm = HuggingFaceEndpoint(
    repo_id="HuggingFaceH4/zephyr-7b-beta",
    task="text-generation",
    max_new_tokens=512,
    do_sample=False,
    repetition_penalty=1.03,
)

chat_model = ChatHuggingFace(llm=llm)
```

```python
from langchain_aws import ChatBedrockConverse

llm = ChatBedrockConverse(
    model_id="anthropic.claude-3-5-sonnet-20240620-v1:0",
    # temperature=...,
    # max_tokens=...,
    # other params...
)
```

*These three examples show how LangChain lets you switch between different LLM providers simply by changing the class you instantiate— `ChatOpenAI`, `ChatHuggingFace`, or `ChatBedrockConverse` — while keeping the rest of your code structure the same.*

*Each class provides access to models from different ecosystems (OpenAI-compatible APIs, Hugging Face, Amazon Bedrock), but they all follow a similar interface for configuration and usage. This illustrates the power of abstraction in LangChain: once you learn the workflow, you can easily work with multiple providers without needing to rewrite your application logic.*

## **Key Takeaway**  

OpenAI’s API is not just a product—it’s become a standard interface for interacting with large language models. By learning its patterns and using tools like LangChain, you’ll be prepared to work with OpenAI, OpenAI-compatible providers, and many others—through a unified approach.

Write once, run anywhere: The same code works across providers by simply changing configuration settings.

This mindset shift—from “learning a single API” to “learning a standard and abstraction” makes you a versatile, future-ready developer, able to integrate AI models across platforms.

*Below are additional resources about the OpenAI API, along with examples of providers that are compatible with the OpenAI API. Notice how they use the OpenAI SDK by simply updating the base_url to point to a different provider.*

<div style="display: flex; gap: 20px; justify-content: center; flex-wrap: wrap;">
  <a href="https://medium.com/data-professor/beginners-guide-to-openai-api-a0420bc58ee5" target="_blank">
    <img src="{{ '/assets/images/open_ai_guide.png' | relative_url }}" alt="OpenAI Guide"
         style="width: 30%; height: auto; border-radius: 8px;" />
  </a>

  <a href="https://docs.anthropic.com/en/api/openai-sdk" target="_blank">
    <img src="{{ '/assets/images/anthropic_open_ai.png' | relative_url }}" alt="Anthropic OpenAI"
         style="width: 30%; height: auto; border-radius: 8px;" />
  </a>

  <a href="https://api-docs.deepseek.com" target="_blank">
    <img src="{{ '/assets/images/deepseek_openai.png' | relative_url }}" alt="DeepSeek OpenAI"
         style="width: 30%; height: auto; border-radius: 8px;" />
  </a>
</div>

---

# 7. LangChain: Framework for Agents

LangChain is a powerful framework that abstracts LLM orchestration and agent behavior.

### 7.1 Core Concepts

* Chains: Sequences of calls to LLMs or tools
* Memory: Context persistence over time
* Tools: Functions the agent can invoke (e.g., web search, code execution)
* Agents: Autonomous decision-makers that choose which tools to use

### 7.2 Agent Types

* **ReAct (Reasoning + Acting)**: Agent reasons before using tools
* **Conversational Agent**: Designed for dialogue with memory
* **Structured Tool Use**: Agents that operate under schema-driven APIs

---

# 8. Prompt Engineering

Prompt engineering is both an art and a science — the design of effective instructions to guide LLM behavior.

### 8.1 Prompt Types

* Zero-shot, one-shot, and few-shot prompts
* Chain-of-thought (CoT) prompting
* Role-based prompts and system instructions

### 8.2 Optimization Techniques

* Output formatting with delimiters
* Step-by-step instructions
* Guardrails and constraints